{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from glob import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from builtins import getattr\n",
    "from genericpath import isdir\n",
    "from templates import *\n",
    "from templates_cls import *\n",
    "from experiment_classifier import ClsModel\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(cond, mean, std):\n",
    "    return (cond - mean.to(cond.device)) / std.to(cond.device)\n",
    "\n",
    "def denormalize(cond, mean, std):\n",
    "    return (cond * std.to(cond.device)) + mean.to(cond.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a, b):\n",
    "    a = a.view(a.shape[0], -1)\n",
    "    b = b.view(b.shape[0], -1)\n",
    "    a = F.normalize(a, dim=1)\n",
    "    b = F.normalize(b, dim=1)\n",
    "    return (a * b).sum(dim=1)\n",
    "\n",
    "def spherical_interpolation(x0, x1, alpha):\n",
    "    theta = th.arccos(cos(x0, x1))\n",
    "    # fix the divid by zero problem with identical ends\n",
    "    coef = ((th.sin(\n",
    "        (1 - alpha) * theta) + 1e-8) / (th.sin(theta) + 1e-8))[:, None,\n",
    "                                                                  None, None]\n",
    "    a = coef * x0\n",
    "    b = (th.sin(alpha * theta) /\n",
    "         (th.sin(theta) + 1e-8))[:, None, None, None] * x1\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def sqrt_interpolation(x0, x1, alpha):\n",
    "    # doesn't work well with identical ends\n",
    "    return ((1 - alpha) * x0 + (alpha) * x1) / math.sqrt(alpha**2 +\n",
    "                                                         (1 - alpha)**2)\n",
    "\n",
    "\n",
    "def linear_interpolation(x0, x1, alpha):\n",
    "    return ((1 - alpha) * x0 + (alpha) * x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 512])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:3'\n",
    "lat = torch.load(f'checkpoints/ffhq256_autoenc/latent_train.pkl', map_location='cpu')\n",
    "data_conds = lat['conds']\n",
    "# data_conds = normalize(lat['conds'], lat['conds_mean'], lat['conds_std'])\n",
    "print(lat['conds'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL SHADOW 612\n"
     ]
    }
   ],
   "source": [
    "label_path = '/home/nontawat/shadow_labels/*.txt'\n",
    "count = 0\n",
    "\n",
    "shadow_img = []\n",
    "normal_img = []\n",
    "\n",
    "\n",
    "for tx in glob(label_path):\n",
    "    f = open(tx, 'r')\n",
    "    line = f.readlines()\n",
    "\n",
    "    for i in range(len(line)):\n",
    "        cls = line[i].split()[-1]\n",
    "        idx = int(line[i].split()[0].split('.')[0])\n",
    "        if cls == '0':\n",
    "            normal_img.append(data_conds[idx])\n",
    "        elif cls == '1':\n",
    "            # print(idx)\n",
    "            shadow_img.append(data_conds[idx])\n",
    "            count+=1\n",
    "            \n",
    "print(f'TOTAL SHADOW {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard_neg = '/home/nontawat/grad_mag.text'\n",
    "# file = open(hard_neg, 'r')\n",
    "# neg_line = file.readlines()\n",
    "# def alg(line):\n",
    "#     de = []\n",
    "#     for i in range(len(line)):\n",
    "#         de.append(tuple(line[i].split('_')))\n",
    "\n",
    "#     sde = sorted(de, key=lambda x: x[1], reverse=False)\n",
    "#     return sde\n",
    "\n",
    "# sorted_hard_neg = alg(neg_line)\n",
    "# norm_neg = []\n",
    "# for i in range(len(sorted_hard_neg)):\n",
    "#     idx = int(sorted_hard_neg[i][0])\n",
    "#     norm_neg.append(data_conds[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(normal_img)\n",
    "sub_norm = normal_img[:len(shadow_img)]\n",
    "# sub_norm = norm_neg[:len(shadow_img)]\n",
    "# len(shadow_img)\n",
    "train_norm = np.stack(sub_norm, axis=0)\n",
    "train_shadow = np.stack(shadow_img, axis=0)\n",
    "norm_label = np.zeros(train_norm.shape[0])\n",
    "shadow_label = np.ones(train_shadow.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612, 512)\n",
      "(612, 512)\n"
     ]
    }
   ],
   "source": [
    "print(train_norm.shape)\n",
    "print(train_shadow.shape)\n",
    "# mnorm = torch.from_numpy(np.mean(train_norm[:2], axis=0)).to(device)\n",
    "# mshad = torch.from_numpy(np.mean(train_shadow[:2],axis=0)).to(device)\n",
    "# direc = mnorm - mshad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 512)\n",
      "(1162,)\n",
      "(62, 512)\n",
      "(62,)\n"
     ]
    }
   ],
   "source": [
    "img = np.concatenate([train_norm, train_shadow], axis=0)\n",
    "label = np.concatenate([norm_label, shadow_label], axis=0)\n",
    "# X, Y = shuffle(img, label, random_state=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(img, label, train_size=0.95)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500000, tol=0.01)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression(tol=1e-2, max_iter=500000, verbose=0)\n",
    "# param = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#     'tol': [1e-2, 1e-4, 1e-6, 1e-8],\n",
    "#     'C':[1e-8, 1e-6, 1e-4, 1e-2, 1, 1.2, 1.4, 2, 3, 4, 10, 100]}\n",
    "# st = StratifiedKFold(n_splits=10)\n",
    "# clf = GridSearchCV(reg, param, cv=st)\n",
    "# clf.fit(img, label)\n",
    "reg.fit(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9223856209150327"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512)\n",
      "[-1.28457544]\n"
     ]
    }
   ],
   "source": [
    "print(reg.coef_.shape)\n",
    "print(reg.intercept_)\n",
    "cls_dict = {}\n",
    "cls_dict['weight'] = reg.coef_\n",
    "cls_dict['bias'] = reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cls_weight.pkl', 'wb') as ob:\n",
    "    pickle.dump(cls_dict, ob, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 512])\n"
     ]
    }
   ],
   "source": [
    "print(data_conds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, torch\n",
    "pkl_file = open('cls_weight.pkl', 'rb')\n",
    "cls_weight = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['weight', 'bias'])\n"
     ]
    }
   ],
   "source": [
    "lat = torch.load(f'checkpoints/ffhq256_autoenc/latent_val.pkl', map_location='cpu')\n",
    "data_conds = lat['conds']\n",
    "print(cls_weight.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 512])\n"
     ]
    }
   ],
   "source": [
    "print(data_conds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = data_conds.numpy()\n",
    "proj_data = ndata@(cls_weight['weight'].T)\n",
    "proj_data_bias = proj_data+cls_weight['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val-shadow.txt', 'w') as f:\n",
    "    for i in range(data_conds.shape[0]):\n",
    "        f.write(f'{60000+i}.jpg {proj_data[i].item()}')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val-shadowbias.txt', 'w') as f:\n",
    "    for i in range(data_conds.shape[0]):\n",
    "        f.write(f'{60000+i}.jpg {proj_data_bias[i].item()}')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.sum())\n",
    "reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD MAIN MODEL\n",
    "conf = ffhq256_autoenc()\n",
    "model = LitModel(conf)\n",
    "state = torch.load(f'/home2/nontawat/diffae_logs/{conf.name}/last.ckpt', map_location='cpu')\n",
    "model.load_state_dict(state['state_dict'], strict=False)\n",
    "model.ema_model.eval()\n",
    "model.ema_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_conf = ffhq256_autoenc_cls()\n",
    "state = torch.load(f'/home2/nontawat/diffae_logs/{cls_conf.name}/last.ckpt',\n",
    "                    map_location='cpu')\n",
    "print('latent step:', state['global_step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state['state_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_id = CelebAttrDataset.cls_to_id['Smiling']\n",
    "# mean = state['state_dict']['conds_mean'].to(device)\n",
    "# std = state['state_dict']['conds_std'].to(device)\n",
    "# weit = state['state_dict']['classifier.weight'][cls_id][None, :].to(device)\n",
    "# print(mean.shape)\n",
    "# print(weit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_val = torch.load(f'checkpoints/ffhq256_autoenc/latent_val.pkl', map_location='cpu')\n",
    "img = Image.open('/home2/nontawat/ffhq_256/valid/60065.jpg')\n",
    "tran = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                            ])\n",
    "imt = tran(img)\n",
    "cond = lat['conds'][65][None, :].to(device)\n",
    "# xT = model.encode_stochastic(imt[None, :].to(device), cond, T=250)\n",
    "# ncond = normalize(cond, mean, std)\n",
    "# ncond = (cond + 0.05 * (torch.from_numpy(reg.coef_).to(device))).float()\n",
    "# ncond = denormalize(ncond, mean, std)\n",
    "print(cond.shape)\n",
    "# print(xT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict_proba(cond.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_val = torch.load(f'checkpoints/ffhq256_autoenc/latent_val.pkl', map_location='cpu')\n",
    "# img = Image.open('/home2/nontawat/ffhq_256/valid/60824.jpg')\n",
    "# tran = torchvision.transforms.Compose([\n",
    "#                             torchvision.transforms.ToTensor(),\n",
    "#                             torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#                             ])\n",
    "# imt = tran(img)\n",
    "# print(imt.shape)\n",
    "# cond = lat_val['conds'][824][None, :].to(device)\n",
    "# xTT = model.encode_stochastic(imt[None, :].to(device), cond, T=250)\n",
    "# xT = torch.randn([1, 3, 256, 256]).to(device)\n",
    "# # ncond = normalize(cond, lat['conds_mean'], lat['conds_std'])\n",
    "# ncond = cond + direc[None, :]\n",
    "# # ncond = denormalize(ncond, lat['conds_mean'], lat['conds_std'])\n",
    "# print(cond.shape)\n",
    "# print(xT.shape)\n",
    "# xT = torch.randn([1, 3, 256, 256]).to(device)\n",
    "# cat = torch.stack([data_conds[2], data_conds[4], data_conds[12], data_conds[13]], dim=0)\n",
    "# mcat = cat.mean(dim=0).to(device)\n",
    "# print(mcat.shape)\n",
    "# ii = model.render(xT, mcat[None, :], T=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = ii[0].permute(1,2,0).cpu().numpy()\n",
    "# plt.imshow((im*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cond1 = (data_conds[12]).to(device)\n",
    "# cond2 = (data_conds[13]).to(device)\n",
    "# xT = torch.randn([1, 3, 256, 256]).to(device)\n",
    "# xT2 = torch.randn([1, 3, 256, 256]).to(device)\n",
    "# with torch.no_grad():\n",
    "#     imgOri1 = model.render(xT, cond1[None, :], T=250)\n",
    "#     imgOri2 = model.render(xT2, cond2[None, :], T=250)\n",
    "# mnorm = denormalize(mnorm, lat['conds_mean'], lat['conds_std'])\n",
    "# mshad = denormalize(mshad, lat['conds_mean'], lat['conds_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list = []\n",
    "# alpha = torch.linspace(0, 1, 7)\n",
    "# for i in range(len(alpha)):\n",
    "#     Xintp = spherical_interpolation(xT, xT2, alpha[i])\n",
    "#     cintp = linear_interpolation(cond1[None, :], cond2[None, :], alpha[i])\n",
    "#     imginp = model.render(Xintp, cintp, T=250)\n",
    "#     img_list.append(imginp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(imgOri1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgt1 = imgOri1[0].permute(1,2,0).cpu().numpy()\n",
    "# imgt2 = imgOri2[0].permute(1,2,0).cpu().numpy()\n",
    "# imgtt = np.concatenate([img_list[i][0].permute(1,2,0).cpu().numpy() for i in range(len(img_list))], axis=1)\n",
    "# imgh = np.concatenate([imgt1, imgtt, imgt2], axis = 1)\n",
    "# plt.imshow((imgh*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgOri = model.render(xT, cond, T=250)\n",
    "# imO = imgOri[0].permute(1, 2, 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reg.coef_.shape)\n",
    "# weit = F.normalize(torch.from_numpy(reg.coef_).to(device), dim=1)\n",
    "\n",
    "# condS = (cond - 2.5*weit).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(141), plt.imshow((imO*255).astype(np.uint8))\n",
    "\n",
    "# imgMod = model.render(xT, ncond, T=250)\n",
    "# imgNom = model.render(xTT, mnorm[None, :], T=250)\n",
    "# imgShad = model.render(xTT, mshad[None, :], T=250)\n",
    "# imMd = imgMod[0].permute(1, 2, 0).cpu().numpy()\n",
    "# imNm = imgNom[0].permute(1, 2, 0).cpu().numpy()\n",
    "# imSd = imgShad[0].permute(1, 2, 0).cpu().numpy()\n",
    "# plt.subplot(142), plt.imshow((imMd*255).astype(np.uint8))\n",
    "# plt.subplot(143), plt.imshow((imNm*255).astype(np.uint8))\n",
    "# plt.subplot(144), plt.imshow((imSd*255).astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_shadow.shape)\n",
    "# xH = torch.randn([612, 3, 256, 256]).to(device)\n",
    "\n",
    "# img = model.render(xH[:8], torch.from_numpy(train_shadow[:8]).to(device), T=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(img.shape)\n",
    "# imgt = img.permute(0, 2, 3, 1).cpu().numpy()\n",
    "# imgh = np.concatenate([imgt[i]  for i in range(8)], axis = 1)\n",
    "# plt.imshow((imgh*255).astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv_pytorch1.9': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "536b1f54227c988ac2a9ee4d5614cd3e5206358e082f2f7b0ebf7d56802afbe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
