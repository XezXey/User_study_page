{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0105f006",
   "metadata": {},
   "source": [
    "# RotateHDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f44949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 (n=10): [(14, '125_hdrmaps_com_free_2K'), (16, '117_hdrmaps_com_free_2K'), (6, '064_hdrmaps_com_free_2K'), (5, '117_hdrmaps_com_free_2K'), (3, '125_hdrmaps_com_free_2K'), (18, '064_hdrmaps_com_free_2K'), (1, '125_hdrmaps_com_free_2K'), (19, '117_hdrmaps_com_free_2K'), (20, '064_hdrmaps_com_free_2K'), (15, '125_hdrmaps_com_free_2K')]\n",
      "  HDR counts in page: {'125_hdrmaps_com_free_2K': 4, '117_hdrmaps_com_free_2K': 3, '064_hdrmaps_com_free_2K': 3}\n",
      "------------------------------------------------------------\n",
      "Page 2 (n=10): [(6, '117_hdrmaps_com_free_2K'), (3, '064_hdrmaps_com_free_2K'), (12, '125_hdrmaps_com_free_2K'), (10, '064_hdrmaps_com_free_2K'), (1, '117_hdrmaps_com_free_2K'), (16, '125_hdrmaps_com_free_2K'), (2, '117_hdrmaps_com_free_2K'), (15, '064_hdrmaps_com_free_2K'), (5, '125_hdrmaps_com_free_2K'), (18, '117_hdrmaps_com_free_2K')]\n",
      "  HDR counts in page: {'117_hdrmaps_com_free_2K': 4, '064_hdrmaps_com_free_2K': 3, '125_hdrmaps_com_free_2K': 3}\n",
      "------------------------------------------------------------\n",
      "Page 3 (n=10): [(5, '064_hdrmaps_com_free_2K'), (3, '117_hdrmaps_com_free_2K'), (10, '125_hdrmaps_com_free_2K'), (14, '064_hdrmaps_com_free_2K'), (13, '125_hdrmaps_com_free_2K'), (11, '117_hdrmaps_com_free_2K'), (7, '064_hdrmaps_com_free_2K'), (12, '117_hdrmaps_com_free_2K'), (8, '125_hdrmaps_com_free_2K'), (17, '064_hdrmaps_com_free_2K')]\n",
      "  HDR counts in page: {'064_hdrmaps_com_free_2K': 4, '117_hdrmaps_com_free_2K': 3, '125_hdrmaps_com_free_2K': 3}\n",
      "------------------------------------------------------------\n",
      "Page 4 (n=10): [(18, '125_hdrmaps_com_free_2K'), (15, '117_hdrmaps_com_free_2K'), (1, '064_hdrmaps_com_free_2K'), (9, '064_hdrmaps_com_free_2K'), (20, '117_hdrmaps_com_free_2K'), (4, '125_hdrmaps_com_free_2K'), (14, '117_hdrmaps_com_free_2K'), (17, '125_hdrmaps_com_free_2K'), (2, '064_hdrmaps_com_free_2K'), (10, '117_hdrmaps_com_free_2K')]\n",
      "  HDR counts in page: {'125_hdrmaps_com_free_2K': 3, '117_hdrmaps_com_free_2K': 4, '064_hdrmaps_com_free_2K': 3}\n",
      "------------------------------------------------------------\n",
      "Page 5 (n=10): [(8, '064_hdrmaps_com_free_2K'), (9, '125_hdrmaps_com_free_2K'), (17, '117_hdrmaps_com_free_2K'), (16, '064_hdrmaps_com_free_2K'), (2, '125_hdrmaps_com_free_2K'), (4, '117_hdrmaps_com_free_2K'), (11, '064_hdrmaps_com_free_2K'), (7, '125_hdrmaps_com_free_2K'), (13, '117_hdrmaps_com_free_2K'), (20, '125_hdrmaps_com_free_2K')]\n",
      "  HDR counts in page: {'064_hdrmaps_com_free_2K': 3, '125_hdrmaps_com_free_2K': 4, '117_hdrmaps_com_free_2K': 3}\n",
      "------------------------------------------------------------\n",
      "Page 6 (n=10): [(13, '064_hdrmaps_com_free_2K'), (19, '125_hdrmaps_com_free_2K'), (9, '117_hdrmaps_com_free_2K'), (12, '064_hdrmaps_com_free_2K'), (6, '125_hdrmaps_com_free_2K'), (7, '117_hdrmaps_com_free_2K'), (4, '064_hdrmaps_com_free_2K'), (8, '117_hdrmaps_com_free_2K'), (11, '125_hdrmaps_com_free_2K'), (19, '064_hdrmaps_com_free_2K')]\n",
      "  HDR counts in page: {'064_hdrmaps_com_free_2K': 4, '125_hdrmaps_com_free_2K': 3, '117_hdrmaps_com_free_2K': 3}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def paginate_many_to_many(\n",
    "    subjects,\n",
    "    hdrs,\n",
    "    chunk_size,\n",
    "    repeats_per_pair=1,\n",
    "    seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build pages of (subject, hdr) tuples from the full Cartesian pool.\n",
    "    \n",
    "    Constraints:\n",
    "      - No subject repeats within a page.\n",
    "      - Minimize HDR repetition within each page; balance HDR usage globally.\n",
    "    \n",
    "    Args:\n",
    "      subjects: list of subject ids (e.g., [1..20])\n",
    "      hdrs: list of hdr names\n",
    "      chunk_size: number of items per page (must be <= len(subjects))\n",
    "      repeats_per_pair: how many times to include each (subject, hdr) pair in the total pool\n",
    "      seed: int, for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "      pages: list[list[tuple]] where each inner list is a page of (subject, hdr)\n",
    "    \"\"\"\n",
    "    assert chunk_size >= 1, \"chunk_size must be >= 1\"\n",
    "    assert chunk_size <= len(subjects), \"chunk_size cannot exceed #subjects (no subject repeat per page)\"\n",
    "\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 1) Build the many-to-many pool (Cartesian product) with optional repeats.\n",
    "    pool = []\n",
    "    for _ in range(repeats_per_pair):\n",
    "        for s in subjects:\n",
    "            for h in hdrs:\n",
    "                pool.append((s, h))\n",
    "\n",
    "    # Shuffle to avoid bias\n",
    "    random.shuffle(pool)\n",
    "\n",
    "    pages = []\n",
    "    global_hdr_counts = Counter()\n",
    "\n",
    "    # 2) Greedily fill pages under constraints\n",
    "    while pool:\n",
    "        page = []\n",
    "        page_subjects = set()\n",
    "        page_hdr_counts = Counter()\n",
    "\n",
    "        # Fill up to chunk_size items\n",
    "        while len(page) < chunk_size:\n",
    "            # Candidates = any pair whose subject not already on the page\n",
    "            candidates_idx = [i for i, (s, h) in enumerate(pool) if s not in page_subjects]\n",
    "            if not candidates_idx:\n",
    "                break  # can't add more to this page; move on\n",
    "\n",
    "            # Score candidates:\n",
    "            #  - Prefer HDR not used in this page (lower page_hdr_counts)\n",
    "            #  - Then lower global usage (global_hdr_counts)\n",
    "            #  - Tiny random jitter to break ties fairly\n",
    "            best_i = None\n",
    "            best_key = None\n",
    "            for i in candidates_idx:\n",
    "                s, h = pool[i]\n",
    "                key = (page_hdr_counts[h], global_hdr_counts[h])\n",
    "                if best_key is None or key < best_key or (key == best_key and random.random() < 0.5):\n",
    "                    best_key = key\n",
    "                    best_i = i\n",
    "\n",
    "            # Place the chosen pair\n",
    "            s, h = pool.pop(best_i)\n",
    "            page.append((s, h))\n",
    "            page_subjects.add(s)\n",
    "            page_hdr_counts[h] += 1\n",
    "            global_hdr_counts[h] += 1\n",
    "\n",
    "            if not pool:\n",
    "                break\n",
    "\n",
    "        if page:\n",
    "            pages.append(page)\n",
    "        else:\n",
    "            # Safety: if we couldn't place anything (shouldn't happen), break to avoid infinite loop\n",
    "            break\n",
    "\n",
    "    return pages\n",
    "\n",
    "# -----------------------\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    sj_id = list(range(1, 21))\n",
    "    hdr_set = \"064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K\".split(\"#\")\n",
    "\n",
    "    pages = paginate_many_to_many(\n",
    "        subjects=sj_id,\n",
    "        hdrs=hdr_set,\n",
    "        chunk_size=10,        # items per page\n",
    "        repeats_per_pair=1,  # each (subject, hdr) appears once in the full pool\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Print a compact summary\n",
    "    # from collections import Counter\n",
    "    # for pi, page in enumerate(pages, 1):\n",
    "    #     hdrs_in_page = [h for _, h in page]\n",
    "    #     print(f\"Page {pi} (n={len(page)}):\", page)\n",
    "    #     print(\"  HDR counts in page:\", dict(Counter(hdrs_in_page)))\n",
    "    #     print(\"-\" * 60)\n",
    "    \n",
    "    if len(pages[-2]) + len(pages[-1]) <= 10:\n",
    "        # Merge last two pages if combined size <= chunk_size\n",
    "        pages[-2].extend(pages[-1])\n",
    "        pages.pop()\n",
    "\n",
    "\n",
    "    # Print a compact summary\n",
    "    from collections import Counter\n",
    "    for pi, page in enumerate(pages, 1):\n",
    "        hdrs_in_page = [h for _, h in page]\n",
    "        print(f\"Page {pi} (n={len(page)}):\", page)\n",
    "        print(\"  HDR counts in page:\", dict(Counter(hdrs_in_page)))\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "\n",
    "    # Save to CSV for MTurk\n",
    "    import pandas as pd\n",
    "    out = {'sj_name': [], 'hdr_name': []}\n",
    "    for page in pages:\n",
    "        sj_tmp = []\n",
    "        hdr_tmp = []\n",
    "        for s, h in page:\n",
    "            sj_tmp.append(f\"pair{s}\")\n",
    "            hdr_tmp.append(h)\n",
    "        out['sj_name'].append(\"#\".join(sj_tmp))\n",
    "        out['hdr_name'].append(\"#\".join(hdr_tmp))\n",
    "    pd.DataFrame(out).to_csv('./rotateHDR.csv', index=False, columns=['sj_name', 'hdr_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc9065",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdf4c6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pair14#pair16#pair6#pair5#pair3#pair18#pair1#pair19#pair20#pair15 125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K\n",
      "1 pair6#pair3#pair12#pair10#pair1#pair16#pair2#pair15#pair5#pair18 117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K\n",
      "2 pair5#pair3#pair10#pair14#pair13#pair11#pair7#pair12#pair8#pair17 064_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K\n",
      "3 pair18#pair15#pair1#pair9#pair20#pair4#pair14#pair17#pair2#pair10 125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K\n",
      "4 pair8#pair9#pair17#pair16#pair2#pair4#pair11#pair7#pair13#pair20 064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K\n",
      "5 pair13#pair19#pair9#pair12#pair6#pair7#pair4#pair8#pair11#pair19 064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K#117_hdrmaps_com_free_2K#125_hdrmaps_com_free_2K#064_hdrmaps_com_free_2K\n",
      "pair14 ['125_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair16 ['117_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K']\n",
      "pair6 ['064_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K']\n",
      "pair5 ['117_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K']\n",
      "pair3 ['125_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair18 ['064_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K']\n",
      "pair1 ['125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K']\n",
      "pair19 ['117_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K']\n",
      "pair20 ['064_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K']\n",
      "pair15 ['125_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair12 ['125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K']\n",
      "pair10 ['064_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair2 ['117_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K']\n",
      "pair13 ['125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K']\n",
      "pair11 ['117_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K']\n",
      "pair7 ['064_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair8 ['125_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair17 ['064_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair9 ['064_hdrmaps_com_free_2K', '125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K']\n",
      "pair4 ['125_hdrmaps_com_free_2K', '117_hdrmaps_com_free_2K', '064_hdrmaps_com_free_2K']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./rotateHDR.csv')\n",
    "sj_dict = {}\n",
    "for i, row in df.iterrows():\n",
    "    print(i, row['sj_name'], row['hdr_name'])\n",
    "    sj = row['sj_name'].split('#')\n",
    "    hdr = row['hdr_name'].split('#')\n",
    "    for j, p in enumerate(sj):\n",
    "        if p not in sj_dict:\n",
    "            sj_dict[p] = [hdr[j]]\n",
    "        else:\n",
    "            sj_dict[p].append(hdr[j])\n",
    "\n",
    "for k, v in sj_dict.items():\n",
    "    print(k, v)\n",
    "    assert len(v) == len(set(v)), f\"Subject {k} has repeated HDRs: {v}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm_sampling_deca_pysh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
